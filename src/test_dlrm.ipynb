{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model.DLRM_Net import DLRM_Net\n",
    "from model.DLRM_Dataset import DLRM_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import common\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test/test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate or Load Ad Copy Embeddings for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or generate ad copy embeddings\n",
    "embeddings_file = 'model_artifacts/ad_copy_embeddings.pkl'\n",
    "if os.path.exists(embeddings_file):\n",
    "    with open(embeddings_file, 'rb') as file:\n",
    "        ad_copy_embeddings_dict = pickle.load(file)\n",
    "else:\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    ad_copy_embeddings_dict = common.generate_all_embeddings(embeddings_file, model, tokenizer, device)\n",
    "\n",
    "# Map embeddings to ad_copy\n",
    "embeddings_list = df_test['ad_copy'].map(ad_copy_embeddings_dict).tolist()\n",
    "ad_copy_embeddings = np.vstack(embeddings_list)\n",
    "\n",
    "# Load PCA model and transform embeddings to reduce dimensions\n",
    "pca_model_path = 'model_artifacts/pca_model.pkl'\n",
    "with open(pca_model_path, 'rb') as file:\n",
    "    pca = pickle.load(file)\n",
    "reduced_embeddings = pca.transform(ad_copy_embeddings)\n",
    "\n",
    "# Scale the reduced embeddings\n",
    "scaled_ad_copy_embeddings = common.load_and_transform_scaler(reduced_embeddings, 'model_artifacts/embeddings_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Encoders and Label Encode Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['location', 'product_type', 'ad_type']\n",
    "\n",
    "# Load the saved label encoders\n",
    "label_encoders = joblib.load('model_artifacts/label_encoders.joblib')\n",
    "\n",
    "# Apply the label encoders to the test data\n",
    "encoded_categorical_data = np.empty((df_test.shape[0], len(categorical_cols)))\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    # Use the loaded label encoder to transform the data\n",
    "    encoded_categorical_data[:, i] = label_encoders[col].transform(df_test[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Continuous Scaler and Scale Continuous Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_fields = ['age', 'site_visit_frequency']\n",
    "df_continuous = df_test[continuous_fields]\n",
    "scaled_continuous_features = common.load_and_transform_scaler(df_continuous, 'model_artifacts/continuous_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = np.hstack((scaled_continuous_features, scaled_ad_copy_embeddings, encoded_categorical_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Encoders and Scaler to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors suitable for training\n",
    "X = torch.tensor(combined_features, dtype=torch.float32)\n",
    "y = torch.tensor(test_df['ad_clicked'].to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "test_dataset = DLRM_Dataset(X, y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Target Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of ads clicked (ad_clicked = 1): 40.50%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate the percentage of 'ad_clicked' equals 1\n",
    "percentage_clicked = (df_test['ad_clicked'].sum() / len(df_test)) * 100\n",
    "\n",
    "print(f\"Percentage of ads clicked (ad_clicked = 1): {percentage_clicked:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "                      # Number of continuous features + ad_copy_embeddings length\n",
    "num_dense_features = len(scaled_continuous_features[0]) + scaled_ad_copy_embeddings.shape[1]  \n",
    "cat_embedding_sizes = [len(label_encoders[col].classes_) for col in categorical_cols]\n",
    "\n",
    "model = DLRM_Net(num_dense_features=num_dense_features, cat_embedding_sizes=cat_embedding_sizes)\n",
    "model.load_state_dict(torch.load('model_artifacts/trained_model.pt'))\n",
    "model.eval()\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct Predictions: 1640\n",
      "Total Incorrect Predictions: 360\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "\n",
    "num_continuous_features = 2  \n",
    "num_embedding_features = len(scaled_ad_copy_embeddings[0])\n",
    "num_categorical_features = 3\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        x_dense = features[:, :num_continuous_features + num_embedding_features]\n",
    "        x_cat = features[:, num_continuous_features + num_embedding_features:num_continuous_features + num_embedding_features + num_categorical_features]\n",
    "\n",
    "        outputs = model(x_dense, x_cat)\n",
    "        predicted = (outputs > 0.5).float().view(-1)\n",
    "\n",
    "        corrects = (predicted == labels.view(-1)).sum().item()\n",
    "        incorrects = (predicted != labels.view(-1)).sum().item()\n",
    "\n",
    "        correct_predictions += corrects\n",
    "        incorrect_predictions += incorrects\n",
    "\n",
    "    print(f\"Total Correct Predictions: {correct_predictions}\")\n",
    "    print(f\"Total Incorrect Predictions: {incorrect_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.6578, Accuracy: 0.8200\n",
      "Precision: 0.7409\n",
      "F1 Score: 0.7936\n",
      "ROC AUC Score: 0.8714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, roc_auc_score\n",
    "\n",
    "total_loss = 0.0\n",
    "total_correct = 0\n",
    "num_samples = 0\n",
    "all_predictions = []\n",
    "all_actuals = []\n",
    "all_probabilities = []\n",
    "\n",
    "num_continuous_features = 2\n",
    "num_embedding_features = len(scaled_ad_copy_embeddings[0])\n",
    "num_categorical_features = 3 \n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        x_dense = features[:, :num_continuous_features + num_embedding_features]\n",
    "        x_cat = features[:, num_continuous_features + num_embedding_features:num_continuous_features + num_embedding_features + num_categorical_features]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(x_dense, x_cat)\n",
    "\n",
    "        predicted = (outputs > 0.5).float().view(-1)\n",
    "\n",
    "        # Store probabilities for ROC AUC calculation\n",
    "        all_probabilities.extend(outputs.view(-1).numpy())\n",
    "\n",
    "        correct = (predicted == labels.view(-1)).sum().item()\n",
    "        total_correct += correct\n",
    "        num_samples += labels.size(0)\n",
    "\n",
    "        all_predictions.extend(predicted.numpy())\n",
    "        all_actuals.extend(labels.view(-1).numpy())\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "avg_loss = total_loss / len(test_loader)\n",
    "test_accuracy = total_correct / num_samples\n",
    "\n",
    "print(f\"Loss: {avg_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_actuals = np.array(all_actuals)\n",
    "all_probabilities = np.array(all_probabilities)\n",
    "\n",
    "precision = precision_score(all_actuals, all_predictions)\n",
    "f1 = f1_score(all_actuals, all_predictions)\n",
    "roc_auc = roc_auc_score(all_actuals, all_probabilities)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
