{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "sys.path.append(\"/home/glaurung/ai-ads\")\n",
    "sys.path.append(\"/home/glaurung/ai-ads/dlrm\")\n",
    "from dlrm import data_utils\n",
    "import dlrm\n",
    "import pickle\n",
    "from dlrm_s_pytorch import DLRM_Net\n",
    "import numpy as np\n",
    "import ad_copy_util\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  user_id  \\\n",
      "1    ae54fb29-6926-49a3-885b-018442017bf0   \n",
      "4    f9fb7b61-a9c5-4659-b8ec-3d7fe3a6e7a7   \n",
      "8    707b3d87-08d3-40d2-9b0e-06e76a9eb3e2   \n",
      "10   ff506cc0-7590-439d-8f08-dcfbd9b86c63   \n",
      "11   08e28cf0-2284-4387-9daa-c308f587e525   \n",
      "..                                    ...   \n",
      "977  d65a4ef1-74b9-4984-b3b8-b39d1de8d7f3   \n",
      "979  7d682efb-3b87-4888-836c-77753b0fc479   \n",
      "983  dedfe98f-2ac1-4d6a-a80c-b547298a8038   \n",
      "989  e36ce2f4-2ac5-4225-813f-54ba4b524cb3   \n",
      "998  cdb8a344-e660-4f2b-a83b-38833d0219e9   \n",
      "\n",
      "                                    ad_id  age device_type       location  \\\n",
      "1    82e95faa-b197-4213-92a9-5b34c203b91f   44      tablet           Asia   \n",
      "4    6e59229f-ef7f-4475-97ea-b88e5a85b9a3   62      mobile  South America   \n",
      "8    403d6863-4488-47c9-9059-6c9c4d2aa2ed   42      mobile  North America   \n",
      "10   5a35b1c7-bad5-4cb9-a1c0-9ab073a99a87   53      mobile  North America   \n",
      "11   62b20cab-240a-447a-bb61-65d63a8e3039   35      tablet  North America   \n",
      "..                                    ...  ...         ...            ...   \n",
      "977  403d6863-4488-47c9-9059-6c9c4d2aa2ed   47     desktop         Europe   \n",
      "979  a93b1115-c2c3-4b27-83e8-fae97be89ab1   22      mobile           Asia   \n",
      "983  a93b1115-c2c3-4b27-83e8-fae97be89ab1   66      tablet           Asia   \n",
      "989  403d6863-4488-47c9-9059-6c9c4d2aa2ed   33     desktop  South America   \n",
      "998  8dd83be0-e769-4194-8dbb-43aa1f8c8506   24     desktop  North America   \n",
      "\n",
      "    browser content_category  \\\n",
      "1    Chrome       automotive   \n",
      "4    Chrome       automotive   \n",
      "8      Edge       technology   \n",
      "10   Chrome           sports   \n",
      "11     Edge       technology   \n",
      "..      ...              ...   \n",
      "977  Safari       technology   \n",
      "979    Edge          fashion   \n",
      "983  Safari          fashion   \n",
      "989  Chrome       technology   \n",
      "998  Safari           travel   \n",
      "\n",
      "                                               ad_copy product_type  \\\n",
      "1    Hit the Road with Confidence, buy one get one ...        books   \n",
      "4    Efficiency Meets Elegance with Aurora Hybrid. ...        books   \n",
      "8    Same great laptop, lower price. Buy one get on...         home   \n",
      "10   Break Records, Not Sweat. Buy one get one free...       beauty   \n",
      "11   Change Your View with OmniLens. Buy one get on...       beauty   \n",
      "..                                                 ...          ...   \n",
      "977  Same great laptop, lower price. Buy one get on...         home   \n",
      "979  Express Yourself with Teacup Smock. Now offeri...     software   \n",
      "983  Express Yourself with Teacup Smock. Now offeri...     software   \n",
      "989  Same great laptop, lower price. Buy one get on...         home   \n",
      "998  Buy one get one free today at TravellorsTranqu...     clothing   \n",
      "\n",
      "     ad_clicked  ... day_of_week interaction_type historical_ad_category  \\\n",
      "1             1  ...    saturday            click                   food   \n",
      "4             1  ...    saturday             view                 travel   \n",
      "8             1  ...      friday             view             technology   \n",
      "10            1  ...     tuesday           ignore                   food   \n",
      "11            0  ...     tuesday            click                 travel   \n",
      "..          ...  ...         ...              ...                    ...   \n",
      "977           1  ...    saturday             view             technology   \n",
      "979           0  ...    thursday             view             technology   \n",
      "983           1  ...   wednesday             view                 health   \n",
      "989           0  ...      friday           ignore                 travel   \n",
      "998           0  ...    thursday            click                   food   \n",
      "\n",
      "    site_visit_duration ads_clicked_this_session  time_spent_on_ad  \\\n",
      "1              8.466662                        3          9.939063   \n",
      "4              0.928430                        3         12.003740   \n",
      "8              0.506552                        3         12.324003   \n",
      "10            13.596330                        1          8.687871   \n",
      "11             1.520149                        3          8.196868   \n",
      "..                  ...                      ...               ...   \n",
      "977            5.833623                        3         13.517497   \n",
      "979            2.637913                        5          7.841042   \n",
      "983           20.761438                        5         11.954245   \n",
      "989           10.705299                        2         11.404625   \n",
      "998            6.924994                        7         10.185530   \n",
      "\n",
      "     pages_visited_this_session  ads_viewed_last_month  \\\n",
      "1                             4                     22   \n",
      "4                             4                     26   \n",
      "8                             3                     20   \n",
      "10                            3                     18   \n",
      "11                            2                     21   \n",
      "..                          ...                    ...   \n",
      "977                           8                     23   \n",
      "979                           6                     22   \n",
      "983                           9                     21   \n",
      "989                           4                     19   \n",
      "998                           5                     16   \n",
      "\n",
      "     avg_time_spent_on_clicked_ads  site_visit_frequency  \n",
      "1                        13.808656             12.153390  \n",
      "4                        11.173057              3.915722  \n",
      "8                        17.256286              0.303670  \n",
      "10                       13.733655              3.654299  \n",
      "11                        5.712598              3.885000  \n",
      "..                             ...                   ...  \n",
      "977                      13.880454              4.400130  \n",
      "979                      11.244629              1.878337  \n",
      "983                      17.448241              0.890035  \n",
      "989                       9.580819              9.021796  \n",
      "998                      15.248322              7.805700  \n",
      "\n",
      "[202 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Filter rows where ad_copy contains \"buy one get one free\"\n",
    "test_df = df_test[df_test['ad_copy'].str.contains(\"buy one get one free\", case=False, na=False)]\n",
    "\n",
    "# df_test = filtered_df\n",
    "\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this section is for POC model deployment. It's not useful for testing because you still need ctr for the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Create a list of 10 catchy phrases that could be used in an advertisement for a new sports drink flavor called Jungle Torrent targeting 20 year old athletes.\"\n",
    "# ad_copy_options = ['1. \"Thirst to Win with Jungle Torrent!\"', '2. \"Start your Winning Streak with Jungle Torrent!\" ', '3. \"Outperform with Jungle Torrent!\"', '4. \"Hydrate to Dominate with Jungle Torrent!\"', '5. \"Stay Energized and Go the Distance with Jungle Torrent!\"', '6. \"Recharge with Jungle Torrent!\"', '7. \"Beat Your Best with Jungle Torrent!\"', '8. \"Go Wild with Jungle Torrent!\"', '9. \"Outpace the Competition with Jungle Torrent!\"', '10. \"Unlock Your Potential with Jungle Torrent!\"']\n",
    "# #ad_copy_util.generate_ad_copy_options(prompt, max_items=10, max_tokens=300, temperature=1)\n",
    "# print(ad_copy_options)\n",
    "\n",
    "# # Use BertModel to generate embeddings instead of OpenAI API to save time and credits.\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"using \", device)\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "# ad_copy_embeddings = ad_copy_util.generate_text_embeddings(ad_copy_options, model, tokenizer, device)\n",
    "# for i, embedding in enumerate(ad_copy_embeddings):\n",
    "#     print(f\"Embedding {i+1} shape: {embedding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare categorical test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {\n",
    "    'ad_id': LabelEncoder(),\n",
    "    'device_type': LabelEncoder(),\n",
    "    'location': LabelEncoder(),\n",
    "    'browser': LabelEncoder(),  \n",
    "    'content_category': LabelEncoder(),\n",
    "    'ad_copy': LabelEncoder(),\n",
    "    'product_type': LabelEncoder(),\n",
    "    'ad_type': LabelEncoder(),\n",
    "    'time_of_day': LabelEncoder(),\n",
    "    'day_of_week': LabelEncoder(),\n",
    "    'interaction_type': LabelEncoder(),\n",
    "    'historical_ad_category': LabelEncoder()\n",
    "}\n",
    "\n",
    "df_categorical_test = common.transform_with_label_encoders(label_encoders, df_test)\n",
    "\n",
    "categorical_features = [tuple(values) for values in df_categorical_test.to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare continuous test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "continuous_fields = ['age', 'site_visit_duration', 'time_spent_on_ad', 'pages_visited_this_session','ads_viewed_last_month', 'avg_time_spent_on_clicked_ads', 'site_visit_frequency']\n",
    "\n",
    "df_continuous = common.load_and_transform_scaler(continuous_fields, df_test)\n",
    "\n",
    "continuous_features = [tuple(values) for values in df_continuous.to_numpy()]\n",
    "\n",
    "target_feature = df_test['ad_clicked'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve ad copy embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_file = 'ad_copy_embeddings.pkl'\n",
    "with open(embeddings_file, 'rb') as file:\n",
    "    ad_copy_embeddings_dict = pickle.load(file)\n",
    "continuous_features_flat = common.prepare_continuous_features_with_embeddings(df_test, df_continuous, ad_copy_embeddings_dict,'ad_copy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the DLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DLRM_Net(\n",
       "  (emb_l): ModuleList(\n",
       "    (0): EmbeddingBag(84, 775, mode='sum')\n",
       "    (1): EmbeddingBag(3, 775, mode='sum')\n",
       "    (2): EmbeddingBag(5, 775, mode='sum')\n",
       "    (3): EmbeddingBag(4, 775, mode='sum')\n",
       "    (4): EmbeddingBag(6, 775, mode='sum')\n",
       "    (5): EmbeddingBag(84, 775, mode='sum')\n",
       "    (6): EmbeddingBag(6, 775, mode='sum')\n",
       "    (7-8): 2 x EmbeddingBag(4, 775, mode='sum')\n",
       "    (9): EmbeddingBag(7, 775, mode='sum')\n",
       "    (10): EmbeddingBag(3, 775, mode='sum')\n",
       "    (11): EmbeddingBag(6, 775, mode='sum')\n",
       "  )\n",
       "  (bot_l): Sequential()\n",
       "  (top_l): Sequential(\n",
       "    (0): Linear(in_features=775, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (loss_fn): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_cardinalities = []\n",
    "\n",
    "# Loop through each category feature and calculate the cardinality\n",
    "for column in label_encoders.keys():\n",
    "    cardinality = len(df_test[column].unique())\n",
    "    category_cardinalities.append(cardinality)\n",
    "\n",
    "category_cardinalities_array = np.array(category_cardinalities)\n",
    "\n",
    "# embedding_sizes: the sizes of the embedding tables based on the cardinalities of the categorical features\n",
    "ln_emb = category_cardinalities_array\n",
    "\n",
    "# original number of continuous features\n",
    "original_m_spa = np.array(continuous_features[0]).shape[0]\n",
    "\n",
    "# size of each ad copy embedding\n",
    "ad_copy_embedding_size = 768  \n",
    "\n",
    "# m_spa is the size of each embedding\n",
    "m_spa = original_m_spa + ad_copy_embedding_size\n",
    "\n",
    "ln_bot = np.array([m_spa])\n",
    "\n",
    "# ln_top = np.array([m_spa + embedding_size * len(categorical_features[0]), 16, 1])\n",
    "ln_top = np.array([775, 16, 1])\n",
    "\n",
    "device = \"cpu\"\n",
    "model = DLRM_Net(\n",
    "    m_spa,\n",
    "    ln_emb,\n",
    "    ln_bot,\n",
    "    ln_top,\n",
    "    arch_interaction_op=\"dot\",\n",
    "    sigmoid_bot=-1,\n",
    "    sigmoid_top=len(ln_top) - 2,\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"/home/glaurung/ai-ads/trained_model.pt\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = torch.tensor(categorical_features, dtype=torch.long)\n",
    "X_cont = torch.tensor(continuous_features_flat, dtype=torch.float32)\n",
    "Y = torch.tensor(target_feature, dtype=torch.float32).view(-1, 1)\n",
    "dataset = TensorDataset(X_cont, X_cat, Y)\n",
    "\n",
    "# Create dataset and data loader\n",
    "test_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.6914\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "test_loss = 0.0\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "with torch.no_grad():\n",
    "    for x_cont, x_cat, y in test_loader:\n",
    "        lS_o, lS_i = common.generate_offsets_and_indices_per_feature(x_cat)\n",
    "        y_pred = model(x_cont, lS_o, lS_i)\n",
    "        loss = criterion(y_pred, y)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Average Test Loss: {avg_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
